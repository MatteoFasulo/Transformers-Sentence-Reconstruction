{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Reconstruction\n",
    "\n",
    "### Deep Learning\n",
    "\n",
    "### Matteo Fasulo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.\n",
    "\n",
    "The otuput can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n",
    "\n",
    "\n",
    "CONSTRAINTS:\n",
    "* No pretrained model can be used.\n",
    "* The neural network models should have less the 20M parameters.\n",
    "* No postprocessing should be done (e.g. no beamsearch)\n",
    "* You cannot use additional training data.\n",
    "\n",
    "\n",
    "BONUS PARAMETERS:\n",
    "\n",
    "A bonus of 0-2 points will be attributed to incentivate the adoption of models with a low number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U keras-nlp tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 20:18:44.000235: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 20:18:45.282052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import re, math, string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.layers import Embedding, Dense, Input\n",
    "from keras.models import Model\n",
    "\n",
    "from keras_nlp.layers import TransformerEncoder, TokenAndPositionEmbedding, TransformerDecoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to heavy GPU memory consumption, Tensorflow has been used with the `memory_growth` option enabled as to not lock the entire GPU memory from the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set memory growth of GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "First a couple of parameters are defined for the entire notebook.\n",
    "\n",
    "- `SEQ_LEN` is the (maximum) length of the input sequence (eventually padded with zeros).\n",
    "- `VOCAB_SIZE` is the size of the vocabulary (max 10000).\n",
    "\n",
    "- `EMBEDDING_DIM` is the dimension of the word embeddings.\n",
    "- `BATCH_SIZE` is the batch size.\n",
    "- `EPOCHS` is the number of epochs for training.\n",
    "- `NUM_ENC_LAYERS` is the number of layers of the encoder.\n",
    "- `NUM_DEC_LAYERS` is the number of layers of the decoder.\n",
    "- `NUM_HEADS` is the number of heads of the multihead attention mechanism.\n",
    "- `LATENT_DIM` is the dimension of the latent space of the transformer (all the feedforward layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 28\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "LATENT_DIM = 1024\n",
    "NUM_ENC_LAYERS = 6\n",
    "NUM_DEC_LAYERS = 6\n",
    "NUM_HEADS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before processing the text, a couple of special tokens are defined. These tokens are used to mark the beginning and end of the sentences as well as encoding comma which otherwise would be removed when preprocessing the text with punctuation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokens:\n",
    "    START = '<start>'\n",
    "    END = '<end>'\n",
    "    COMMA = '<comma>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset is composed by sentences taken from the generics_kb dataset of hugging face. We restricted the vocabolary to the 10K most frequent words, and only took sentences making use of this vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the dataset and preprocess it by filtering only the sentences that have at least 9 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ds = load_dataset('generics_kb', trust_remote_code=True)['train']\n",
    "\n",
    "# Filter out sentences that are too short\n",
    "ds = ds.filter(lambda row: len(row[\"generic_sentence\"].split(\" \")) > 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can add the start and end tokens to the sentences. Replacing comma with a special token to avoid its removal during preprocessing.\n",
    "\n",
    "The entire process is vectorized to speed up the procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a vectorized function\n",
    "vec_func = np.vectorize(\n",
    "    lambda x: f'{Tokens.START} ' + x.replace(',', f' {Tokens.COMMA}') + f' {Tokens.END}')\n",
    "\n",
    "# Apply the function to the 'generic_sentence' column of the DataFrame\n",
    "corpus = vec_func(ds['generic_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom preprocessing function is applied to the dataset. Instead of removing all the punctuation, we replace the comma with a special token as well as the greater and smaller signs. The rest of the punctuation is removed and all the sentences are lowercased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessing(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the given text by removing punctuation and converting it to lowercase.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        str: The preprocessed text.\n",
    "    \"\"\"\n",
    "    chars = string.punctuation\n",
    "    chars = chars.replace(\",\", \"\")\n",
    "    chars = chars.replace(\"<\", \"\")\n",
    "    chars = chars.replace(\">\", \"\")\n",
    "    # Remove punctuation\n",
    "    text = tf.strings.regex_replace(text, '[%s]' % re.escape(chars), '')\n",
    "    # Lowercase\n",
    "    text = tf.strings.lower(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization\n",
    "\n",
    "After preprocessing the text, we can vectorize it using `TextVectorization` layer from tensorflow to convert the text to a sequence of integers. This operation is applied after adding the special tokens as to have them encoded as well into the vocabulary. The vocabulary size is 10K and if the sentences are shorter than the maximum length, they are padded with zeros by means of `output_sequence_length` and the `pad_to_max_tokens` parameters.\n",
    "\n",
    "In this case, the output will be integers each of them representing a word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 20:18:58.467831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Create a TextVectorization layer\n",
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    standardize=custom_preprocessing,\n",
    "    output_sequence_length=SEQ_LEN,\n",
    "    output_mode='int',\n",
    "    pad_to_max_tokens=True,\n",
    ")\n",
    "\n",
    "# Adapt the layer to the dataset\n",
    "tokenizer.adapt(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the vocabulary and the first 10 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '<start>', '<end>', 'the', 'of', 'and', '<comma>', 'is', 'to']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocabulary()\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Detokenizer\n",
    "\n",
    "To convert the integers back to text, we can define a custom detokenizer function that takes in input the integers and returns the corresponding text. This function is used to convert the output of the model back to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDetokenizer:\n",
    "    def __init__(self, vectorize_layer):\n",
    "        self.vectorize_layer = vectorize_layer\n",
    "        vocab = self.vectorize_layer.get_vocabulary()\n",
    "        self.index_to_word = {index: word for index, word in enumerate(vocab)}\n",
    "\n",
    "    def __detokenize_tokens(self, tokens):\n",
    "        def check_token(t):\n",
    "            if t == 2:\n",
    "                s = \"<start>\"\n",
    "            elif t == 3:\n",
    "                s = \"<end>\"\n",
    "            elif t == 7:\n",
    "                s = \"<comma>\"\n",
    "            else:\n",
    "                s = self.index_to_word.get(t, '[UNK]')\n",
    "            return s\n",
    "\n",
    "        return ' '.join([check_token(token) for token in tokens if token != 0])\n",
    "\n",
    "    def __call__(self, batch_tokens):\n",
    "        return [self.__detokenize_tokens(tokens) for tokens in batch_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenizer = TextDetokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem with OOV\n",
    "\n",
    "The model will not be able to generate words that are not in the vocabulary. To overcome this issue, we can remove from our dataset all the sentences that contain words not in the vocabulary. This way we can avoid the model to generate OOV tokens.\n",
    "\n",
    "In the following cell, we first encode all the sentences and then check if there are more than 1 [UNK] token in the sentence. If so, we discard the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241194, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the text to tokens\n",
    "sentences = tokenizer( corpus ).numpy()\n",
    "\n",
    "# Find sentences with more than one [UNK] token\n",
    "mask = np.sum( (sentences==1), axis=1) >= 1\n",
    "\n",
    "# Remove them from the dataset\n",
    "original_data = np.delete( sentences, mask , axis=0)\n",
    "\n",
    "original_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "The original data generator was modified changing the inheriting class from `keras.utils.Sequence` to `keras.utils.PyDataset` which is supported in Keras 3 for passing directly the data to the model `fit` method.\n",
    "\n",
    "Changes applied to the generator:\n",
    "\n",
    "- `math.ceil` is used during the computation of the number of batches of the dataset.\n",
    "- `__getitem__` now returns a tuple `(enc_in, dec_in), dec_out` with encoder and decoder inputs and decoder output.\n",
    "\n",
    "More in detail, the generator returns the following:\n",
    "\n",
    "* The input of the encoder is the shuffled sentence.\n",
    "* the input of the decoder is the original sentence. \n",
    "* The output of the decoder is the original sentence shifted by one position (including end token but not start token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.PyDataset):\n",
    "    def __init__(self, data, batch_size=32, shuffle=True, seed=42, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.data) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        data_batch = np.array([self.data[k] for k in indexes], dtype=np.int16)\n",
    "        # copy of ordered sequences\n",
    "        result = np.copy(data_batch)\n",
    "\n",
    "        # shuffle only the relevant positions for each batch\n",
    "        for i in range(data_batch.shape[0]):\n",
    "            np.random.shuffle(data_batch[i, 1:data_batch[i].argmin() - 1])\n",
    "\n",
    "        # (encoder_input, decoder_input), decoder_output\n",
    "        encoder_input = data_batch\n",
    "        decoder_input = np.copy(result)\n",
    "        decoder_output = np.copy(result)\n",
    "        decoder_output = decoder_output[:, 1:]\n",
    "\n",
    "        # Add a column of zeros at the end\n",
    "        decoder_output = np.pad(decoder_output, [[0, 0], [0, 1]], mode='constant')\n",
    "\n",
    "        return (encoder_input, decoder_input), decoder_output\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        if self.shuffle:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed)\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data\n",
    "\n",
    "The entire dataset is shuffled and split into training and validation sets. The training set contains 220K sentences and the validation set 15K sentences. Both the generators share the same batch size for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a random permutation of training and test set\n",
    "np.random.seed(42)\n",
    "# Shuffle the all data\n",
    "shuffled_indices = np.random.permutation(len(original_data))\n",
    "shuffled_data = original_data[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_generator = DataGenerator(shuffled_data[:220000], batch_size=BATCH_SIZE)\n",
    "val_generator = DataGenerator(shuffled_data[220000:235000], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let s be the source string and p your prediction. The quality of the results will be measured according to the following metric:\n",
    "\n",
    "1.  look for the longest substring w between s and p\n",
    "2.  compute |w|/max(|s|,|p|)\n",
    "\n",
    "If the match is exact, the score is 1.\n",
    "\n",
    "When computing the score, the start and end tokens are not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "def score(s, p):\n",
    "    match = SequenceMatcher(None, s, p).find_longest_match()\n",
    "    # print(match.size)\n",
    "    return (match.size/max(len(p), len(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your score is  0.5423728813559322\n"
     ]
    }
   ],
   "source": [
    "original = \"at first henry wanted to be friends with the king of france\"\n",
    "generated = \"henry wanted to be friends with king of france at the first\"\n",
    "\n",
    "print(\"your score is \", score(original, generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The model is composed by an encoder-decoder architecture with a transformer as the main component. The encoder is composed by a stack of `NUM_ENC_LAYERS` layers, each of them composed by a multihead attention mechanism and a feedforward layer. The decoder is composed by a stack of `NUM_DEC_LAYERS` layers, each of them composed by a multihead attention mechanism, a feedforward layer and an additional multihead attention mechanism that takes the encoder output as input. \n",
    "\n",
    "The output of the decoder is passed through a dense layer without activation function to produce the logits.\n",
    "\n",
    "Due to the fact that the input sequence is shuffled, the encoder does not have a Positional Encoding layer but just an Embedding layer. The decoder instead has both the Embedding layer and the Positional Encoding layer as to take into account the position of the words in the (correct) sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformer(embedding_dim, number_encoding_layers, number_decoding_layers, number_heads, dff, seq_len, vocab_size, dropout_rate):\n",
    "    \"\"\"\n",
    "    Create a transformer model for sentence reconstruction.\n",
    "\n",
    "    Args:\n",
    "        embedding_dim (int): The dimensionality of the token embeddings.\n",
    "        number_encoding_layers (int): The number of encoding layers in the transformer.\n",
    "        number_decoding_layers (int): The number of decoding layers in the transformer.\n",
    "        number_heads (int): The number of attention heads in the transformer.\n",
    "        dff (int): The dimensionality of the feed-forward network in the transformer.\n",
    "        seq_len (int): The length of the input sequences.\n",
    "        vocab_size (int): The size of the vocabulary.\n",
    "        dropout_rate (float): The dropout rate to apply in the transformer.\n",
    "\n",
    "    Returns:\n",
    "        model (keras.Model): The created transformer model.\n",
    "\n",
    "    \"\"\"\n",
    "    # Encoder input\n",
    "    enc_id_input = Input(\n",
    "      shape=(seq_len,),\n",
    "      name=\"token_id_enc\",\n",
    "    )\n",
    "\n",
    "    # Decoder input\n",
    "    dec_id_input = Input(\n",
    "        shape=(seq_len,),\n",
    "        name=\"token_id_dec\",\n",
    "    )\n",
    "\n",
    "    # Encoder Token Embedding, no Position Embedding since the input is shuffled\n",
    "    emb_enc = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim\n",
    "        )(enc_id_input)\n",
    "\n",
    "    # Stack the encoder layers\n",
    "    encoder_layers = []\n",
    "    for i in range(number_encoding_layers):\n",
    "        encoder_layer = TransformerEncoder(\n",
    "        num_heads=number_heads,\n",
    "        intermediate_dim=dff,\n",
    "        dropout=dropout_rate,\n",
    "        name=\"encoder\"+str(i)\n",
    "        )\n",
    "        encoder_layers.append(encoder_layer)\n",
    "\n",
    "    # Apply encoder layers\n",
    "    encoder_seq = emb_enc\n",
    "    for encoder_layer in encoder_layers:\n",
    "        encoder_seq = encoder_layer(encoder_seq)\n",
    "\n",
    "    # Decoder Token and Position Embedding\n",
    "    emb_dec = TokenAndPositionEmbedding(\n",
    "      vocabulary_size=vocab_size,\n",
    "      sequence_length=seq_len,\n",
    "      embedding_dim=embedding_dim,\n",
    "      name=\"dec_emb\",\n",
    "    )(dec_id_input)\n",
    "    # Stack the decoder layers\n",
    "    decoder_layers = []\n",
    "    for i in range(number_decoding_layers):\n",
    "        decoder_layer = TransformerDecoder(\n",
    "        num_heads=number_heads,\n",
    "        intermediate_dim=dff,\n",
    "        dropout=dropout_rate,\n",
    "        name=\"decoder\"+str(i)\n",
    "        )\n",
    "        decoder_layers.append(decoder_layer)\n",
    "    # Apply decoder layers\n",
    "    decoder_seq = emb_dec\n",
    "    for decoder_layer in decoder_layers:\n",
    "        decoder_seq = decoder_layer(encoder_sequence=encoder_seq, decoder_sequence=decoder_seq)\n",
    "\n",
    "    # Output layer with simple Dense layer\n",
    "    outputs = Dense(vocab_size)(decoder_seq)\n",
    "\n",
    "    model = Model(inputs=[enc_id_input, dec_id_input], outputs=outputs)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler\n",
    "\n",
    "THe following learning rate scheduler from the original Transformer paper is used. The learning rate is increased linearly in the first `warmup_steps` steps and then decreased proportionally to the inverse square root of the step number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * tf.cast((self.warmup_steps ** -1.5), dtype=tf.float32)\n",
    "    \n",
    "    return tf.math.rsqrt(tf.cast(self.d_model, dtype=tf.float32)) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function and Accuracy\n",
    "\n",
    "Even if the we pass to the model the sequences as tensors of integers, the loss function is computed on the one-hot encoded version of the (true) sequence. This allows to introduce the label smoothing technique to avoid overfitting as described in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "Regarding the accuracy, it is a masked accuracy where we check if the predicted token is equal to the true token only if the true token is not a padding token and the operation is performed on the entire sequence element-wise.\n",
    "\n",
    "For both the loss and the accuracy, an average is then computed to get a single scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "    \"\"\"\n",
    "    Calculates the masked loss for a given label and prediction.\n",
    "\n",
    "    Args:\n",
    "        label: The true label values.\n",
    "        pred: The predicted values.\n",
    "\n",
    "    Returns:\n",
    "        The masked loss value.\n",
    "\n",
    "    \"\"\"\n",
    "    label = tf.cast(label, tf.int64)\n",
    "    mask = label != 0\n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction='none', label_smoothing=0.1)\n",
    "    label = tf.one_hot(label, depth=VOCAB_SIZE)\n",
    "    loss = loss_object(label, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    res = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    \"\"\"\n",
    "    Calculates the masked accuracy of the predicted labels.\n",
    "\n",
    "    Args:\n",
    "        label (tf.Tensor): The true labels.\n",
    "        pred (tf.Tensor): The predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The masked accuracy.\n",
    "\n",
    "    \"\"\"\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    # Match is when the prediction is equal to the label\n",
    "    match = tf.math.equal(label, pred)\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(label, 0))\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate the model and compile it using the AdamW optimizer and the custom loss function. The model is then trained for `EPOCHS` epochs using the training and validation generators.\n",
    "\n",
    "A small dropout is applied to the output of the encoder and the output of the decoder to avoid overfitting.\n",
    "\n",
    "AdamW parameters are set to the one from the original paper. To better avoid the overfitting, the model integrates weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_id_enc        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ token_id_enc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder0            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">329,856</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">329,856</span> │ encoder0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">329,856</span> │ encoder1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">329,856</span> │ encoder2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_id_dec        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder4            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">329,856</span> │ encoder3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_emb             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,283,584</span> │ token_id_dec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder5            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">329,856</span> │ encoder4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder0            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,160</span> │ dec_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ encoder5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,160</span> │ decoder0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ encoder5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,160</span> │ decoder1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ encoder5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,160</span> │ decoder2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ encoder5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder4            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,160</span> │ decoder3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ encoder5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder5            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,160</span> │ decoder4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ encoder5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290,000</span> │ decoder5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_id_enc        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,280,000\u001b[0m │ token_id_enc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder0            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m329,856\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m329,856\u001b[0m │ encoder0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m329,856\u001b[0m │ encoder1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m329,856\u001b[0m │ encoder2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_id_dec        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder4            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m329,856\u001b[0m │ encoder3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_emb             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,283,584\u001b[0m │ token_id_dec[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder5            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m329,856\u001b[0m │ encoder4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder0            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,160\u001b[0m │ dec_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ encoder5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,160\u001b[0m │ decoder0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ encoder5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,160\u001b[0m │ decoder1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ encoder5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,160\u001b[0m │ decoder2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ encoder5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder4            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,160\u001b[0m │ decoder3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ encoder5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder5            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,160\u001b[0m │ decoder4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ encoder5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m1,290,000\u001b[0m │ decoder5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,209,680</span> (31.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,209,680\u001b[0m (31.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,209,680</span> (31.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,209,680\u001b[0m (31.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropout_rate = 0.1\n",
    "keras_transformer = create_transformer(EMBEDDING_DIM, NUM_ENC_LAYERS, NUM_DEC_LAYERS, NUM_HEADS, LATENT_DIM, SEQ_LEN, VOCAB_SIZE, dropout_rate)\n",
    "\n",
    "learning_rate = CustomSchedule(d_model=EMBEDDING_DIM, warmup_steps=4000)\n",
    "optimizer = AdamW(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9, weight_decay = 0.005)\n",
    "keras_transformer.compile(optimizer=optimizer, loss=masked_loss, metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the model has less than 10M parameters (indeed satisfying the constraints) and the training is quite fast.\n",
    "\n",
    "To have an estimate of how the training is going, we can use the validation generator to compute the loss and accuracy on the validation set.\n",
    "\n",
    "A couple of callbacks were also added to ensure the model is saved only if the validation loss is decreasing and for logging the training history.\n",
    "\n",
    "EarlyStopping, in particular, is used to stop the training if the validation loss does not decrease for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718137195.587420  416045 service.cc:145] XLA service 0x76e98c001dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718137195.587458  416045 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-06-11 20:19:57.799962: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-11 20:20:05.345917: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718137278.829380  416199 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 652 bytes spill stores, 824 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137278.930345  416203 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_411', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137278.934540  416202 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_411', 176 bytes spill stores, 148 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137280.653398  416198 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137282.790585  416200 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_672', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137283.037639  416198 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_674', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137283.799321  416199 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_672', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137286.798003  416200 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_674', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137286.907726  416199 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_674', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137286.927684  416203 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_672', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137288.351326  416199 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_674', 24 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137367.471906  416045 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_105', 16 bytes spill stores, 16 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_104', 448 bytes spill stores, 616 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_95', 4 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137367.599939  416045 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m847/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 8.1357 - masked_accuracy: 0.1326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718137482.373940  416781 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_672', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137482.910320  416777 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_672', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137486.217036  416780 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_411', 260 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137486.763522  416781 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_674', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137486.914432  416784 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_674', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137493.011333  416778 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_674', 396 bytes spill stores, 396 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137493.137466  416783 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137493.803645  416784 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137494.127338  416780 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 652 bytes spill stores, 824 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137572.264968  416045 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_106', 16 bytes spill stores, 16 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_105', 4136 bytes spill stores, 4552 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 52 bytes spill stores, 48 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_95', 4 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 8.1179 - masked_accuracy: 0.1342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718137585.152822  417220 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137586.218012  417220 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137587.294935  417222 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 476 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718137588.305128  417222 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 5.00559, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 264ms/step - loss: 8.1166 - masked_accuracy: 0.1343 - val_loss: 5.0056 - val_masked_accuracy: 0.4172\n",
      "Epoch 2/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 4.5734 - masked_accuracy: 0.4690\n",
      "Epoch 2: val_loss improved from 5.00559 to 3.31271, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 4.5724 - masked_accuracy: 0.4692 - val_loss: 3.3127 - val_masked_accuracy: 0.6287\n",
      "Epoch 3/50\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.1928 - masked_accuracy: 0.6407\n",
      "Epoch 3: val_loss improved from 3.31271 to 2.64583, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 3.1926 - masked_accuracy: 0.6407 - val_loss: 2.6458 - val_masked_accuracy: 0.7193\n",
      "Epoch 4/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.6284 - masked_accuracy: 0.7166\n",
      "Epoch 4: val_loss improved from 2.64583 to 2.39065, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 2.6283 - masked_accuracy: 0.7166 - val_loss: 2.3906 - val_masked_accuracy: 0.7578\n",
      "Epoch 5/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.3529 - masked_accuracy: 0.7566\n",
      "Epoch 5: val_loss improved from 2.39065 to 2.22575, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - loss: 2.3528 - masked_accuracy: 0.7567 - val_loss: 2.2257 - val_masked_accuracy: 0.7803\n",
      "Epoch 6/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.1601 - masked_accuracy: 0.7864\n",
      "Epoch 6: val_loss improved from 2.22575 to 2.12274, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 2.1601 - masked_accuracy: 0.7864 - val_loss: 2.1227 - val_masked_accuracy: 0.7970\n",
      "Epoch 7/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.0211 - masked_accuracy: 0.8112\n",
      "Epoch 7: val_loss improved from 2.12274 to 2.04076, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 2.0211 - masked_accuracy: 0.8112 - val_loss: 2.0408 - val_masked_accuracy: 0.8101\n",
      "Epoch 8/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.9279 - masked_accuracy: 0.8290\n",
      "Epoch 8: val_loss improved from 2.04076 to 2.00241, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - loss: 1.9279 - masked_accuracy: 0.8290 - val_loss: 2.0024 - val_masked_accuracy: 0.8169\n",
      "Epoch 9/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.8619 - masked_accuracy: 0.8427\n",
      "Epoch 9: val_loss improved from 2.00241 to 1.96721, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - loss: 1.8619 - masked_accuracy: 0.8427 - val_loss: 1.9672 - val_masked_accuracy: 0.8262\n",
      "Epoch 10/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.8061 - masked_accuracy: 0.8549\n",
      "Epoch 10: val_loss improved from 1.96721 to 1.95786, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - loss: 1.8061 - masked_accuracy: 0.8549 - val_loss: 1.9579 - val_masked_accuracy: 0.8286\n",
      "Epoch 11/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.7636 - masked_accuracy: 0.8651\n",
      "Epoch 11: val_loss improved from 1.95786 to 1.95143, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - loss: 1.7637 - masked_accuracy: 0.8651 - val_loss: 1.9514 - val_masked_accuracy: 0.8319\n",
      "Epoch 12/50\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.7306 - masked_accuracy: 0.8728\n",
      "Epoch 12: val_loss did not improve from 1.95143\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - loss: 1.7306 - masked_accuracy: 0.8728 - val_loss: 1.9557 - val_masked_accuracy: 0.8305\n",
      "Epoch 13/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.6982 - masked_accuracy: 0.8812\n",
      "Epoch 13: val_loss improved from 1.95143 to 1.93591, saving model to keras_transformer_custom_loss_v3.weights.h5\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 1.6983 - masked_accuracy: 0.8812 - val_loss: 1.9359 - val_masked_accuracy: 0.8357\n",
      "Epoch 14/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.6717 - masked_accuracy: 0.8882\n",
      "Epoch 14: val_loss did not improve from 1.93591\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - loss: 1.6717 - masked_accuracy: 0.8882 - val_loss: 1.9387 - val_masked_accuracy: 0.8386\n",
      "Epoch 15/50\n",
      "\u001b[1m859/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.6509 - masked_accuracy: 0.8934\n",
      "Epoch 15: val_loss did not improve from 1.93591\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 45ms/step - loss: 1.6509 - masked_accuracy: 0.8934 - val_loss: 1.9482 - val_masked_accuracy: 0.8392\n",
      "Epoch 16/50\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.6313 - masked_accuracy: 0.8983\n",
      "Epoch 16: val_loss did not improve from 1.93591\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 45ms/step - loss: 1.6313 - masked_accuracy: 0.8983 - val_loss: 1.9422 - val_masked_accuracy: 0.8409\n",
      "Epoch 17/50\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.6135 - masked_accuracy: 0.9034\n",
      "Epoch 17: val_loss did not improve from 1.93591\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - loss: 1.6135 - masked_accuracy: 0.9034 - val_loss: 1.9437 - val_masked_accuracy: 0.8403\n",
      "Epoch 18/50\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.5964 - masked_accuracy: 0.9080\n",
      "Epoch 18: val_loss did not improve from 1.93591\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - loss: 1.5965 - masked_accuracy: 0.9080 - val_loss: 1.9473 - val_masked_accuracy: 0.8415\n"
     ]
    }
   ],
   "source": [
    "name = 'keras_transformer_custom_loss_v3'\n",
    "\n",
    "history = keras_transformer.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode = \"min\", patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(f'{name}.weights.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "        tf.keras.callbacks.CSVLogger(f\"{name}.csv\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Accuracy Plot\n",
    "\n",
    "The training history is shown below in graphs showing loss and accuracy on the training and validation sets.\n",
    "Also, the learning rate schedule is shown with respect to the number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total steps:  4608\n",
      "total epochs:  18\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print number of steps and epochs done\n",
    "print(\"total steps: \", len(history.history[\"loss\"])*BATCH_SIZE)\n",
    "print(\"total epochs: \", len(history.history[\"loss\"]))\n",
    "#plot accuracy\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['masked_accuracy'], label=\"train\")\n",
    "plt.plot(history.history['val_masked_accuracy'], label=\"validation\")\n",
    "#draw a red point at the best epoch for validation accuracy\n",
    "best_epoch=np.argmax(history.history['val_masked_accuracy'])\n",
    "plt.plot(best_epoch,history.history['val_masked_accuracy'][best_epoch],'ro', label=\"best epoch\")\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "#plot loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label=\"train\")\n",
    "plt.plot(history.history['val_loss'], label=\"validation\")\n",
    "#draw a red point at the best epoch for validation loss\n",
    "best_epoch=np.argmin(history.history['val_loss'])\n",
    "plt.plot(best_epoch,history.history['val_loss'][best_epoch],'ro', label=\"best epoch\")\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model showed a good performance on the validation set with respect to the training set, and the loss decreased quite fast. However, starting from epoch 12 the loss on the validation set started to increase, and the training was stopped at epoch 17 due to the EarlyStopping callback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on unseen data\n",
    "\n",
    "Let's test the model on some unseen data. We can start taking a sentence from the dataset in the very ending part (235000+) and choose randomly 3k instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random subset of 3k samples to evaluate the model\n",
    "\n",
    "start_idx = 235000\n",
    "end_idx = shuffled_data.shape[0]\n",
    "\n",
    "random_sample = np.random.choice(np.arange(start_idx, end_idx), size=3000, replace=False) # Without replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can take the indices of the randomly selected instances and use them to extract the sentences from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(shuffled_data[random_sample], batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing score\n",
    "\n",
    "To test the performance of the model, we can query the test generator. Then the testing phase involves query multiple times the model with the `predict` method and then compute the score. Each time we predict the next token and we use the tokens found so far as input for the next prediction (autoregressive loop). In this way we can generate the entire sentence token by token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of samples:  3000\n",
      "Average score:  0.5099087170938909\n",
      "Standard deviation:  0.280557539956132\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for inputs, _ in test_generator:\n",
    "    encoder_in, decoder_in = inputs\n",
    "    current_batch_size = encoder_in.shape[0]\n",
    "    \n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    start = np.array(vocab.index(Tokens.START), ndmin=1)\n",
    "    output_array = output_array.write(0, tf.tile(start, [current_batch_size]))\n",
    "\n",
    "    for i in range(SEQ_LEN):\n",
    "        output = tf.transpose(output_array.stack())\n",
    "        predictions = keras_transformer.predict((encoder_in, output), verbose=0)\n",
    "\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "        output_array = output_array.write(i+1, predicted_id[:, 0])\n",
    "\n",
    "        end_mask = tf.reduce_any(tf.equal(predicted_id, vocab.index(Tokens.END)), axis=-1)\n",
    "        if tf.reduce_all(end_mask):\n",
    "            break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    output = output.numpy()\n",
    "    output = detokenizer(output)\n",
    "    y = detokenizer(decoder_in)\n",
    "\n",
    "    for predicted, real in zip(output, y):\n",
    "        predicted = predicted.replace(Tokens.START, \"\").replace(Tokens.END, \"\").replace(f\" {Tokens.COMMA}\", \",\").strip()\n",
    "        real = real.replace(Tokens.START, \"\").replace(Tokens.END, \"\").replace(f\" {Tokens.COMMA}\", \",\").strip()\n",
    "        scores.append(score(real, predicted))\n",
    "\n",
    "print(\"\\nNumber of samples: \", len(scores))\n",
    "print(\"Average score: \", np.mean(scores))\n",
    "print(\"Standard deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Score ~0.51 with std 0.28 evaluated on 3000 instances of the test set (randomly selected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The proposed Transformer model showed a good performance in reconstructing the original sentence from a shuffled version of it.\n",
    "\n",
    "Other approaches like Seq2Seq with LSTM encoder and decoder failed to caputer long-term dependencies and syntactic structures of the sentences. The transformer model instead showed a good performance in this task.\n",
    "\n",
    "The proposed Transformer model has less than 10M parameters and is able to achieve a good performance on the test set. A more hyperparametrized model could achieve better results but would not satisfy the constraints of the project.\n",
    "\n",
    "The model could be further improved by increasing the number of layers and the dimension of the latent space, but this would require more parameters and would not satisfy the constraints of the project. Moreover, the `EMBEDDING_DIM` parameter had a cruicial role in determining the number of parameters of the model. Increasing the embedding dimension was leading to a Transformer of around 15M parameters having barely a +0.01 increase in the score.\n",
    "\n",
    "Among the two solutions, I choose the one with the lowest number of parameters as it was more challenging and interesting to work with.\n",
    "\n",
    "> Note: The model could be further improved by injecting into the loss function some preference over longer sequences rather than just the correct token in the correct position. This could be done by adding a term to the loss function that penalizes the model for generating shorter sequences. This would require a custom loss function (still differentiable) and would be a good improvement to the model. I tried this approach but it required more time to train the model and indeed it was just a +0.01 on the score (not worth the time). The idea behind this intuition was that the model could have been more penalized for generating shorter sequences and thus it would have been forced to generate longer sequences and it was all done by using the 1-complement of the `score` function added as a multiplicative factor to the loss value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
